[
  {
    "filename": "airflow-core/src/airflow/executors/local_executor.py",
    "status": "modified",
    "additions": 34,
    "deletions": 3,
    "patch": "@@ -142,6 +142,7 @@ class LocalExecutor(BaseExecutor):\n     \"\"\"\n \n     is_local: bool = True\n+    is_mp_using_fork: bool = multiprocessing.get_start_method() == \"fork\"\n \n     serve_logs: bool = True\n \n@@ -163,6 +164,11 @@ def start(self) -> None:\n         # (it looks like an int to python)\n         self._unread_messages = multiprocessing.Value(ctypes.c_uint)\n \n+        if self.is_mp_using_fork:\n+            # This creates the maximum number of worker processes (parallelism) at once\n+            # to minimize gc freeze/unfreeze cycles when using fork in multiprocessing\n+            self._spawn_workers_with_gc_freeze(self.parallelism)\n+\n     def _check_workers(self):\n         # Reap any dead workers\n         to_remove = set()\n@@ -186,9 +192,14 @@ def _check_workers(self):\n         # via `sync()` a few times before the spawned process actually starts picking up messages. Try not to\n         # create too much\n         if num_outstanding and len(self.workers) < self.parallelism:\n-            # This only creates one worker, which is fine as we call this directly after putting a message on\n-            # activity_queue in execute_async\n-            self._spawn_worker()\n+            if self.is_mp_using_fork:\n+                # This creates the maximum number of worker processes at once\n+                # to minimize gc freeze/unfreeze cycles when using fork in multiprocessing\n+                self._spawn_workers_with_gc_freeze(self.parallelism - len(self.workers))\n+            else:\n+                # This only creates one worker, which is fine as we call this directly after putting a message on\n+                # activity_queue in execute_async when using spawn in multiprocessing\n+                self._spawn_worker()\n \n     def _spawn_worker(self):\n         p = multiprocessing.Process(\n@@ -205,6 +216,26 @@ def _spawn_worker(self):\n             assert p.pid  # Since we've called start\n         self.workers[p.pid] = p\n \n+    def _spawn_workers_with_gc_freeze(self, spawn_number):\n+        \"\"\"\n+        Freeze the GC before forking worker process and unfreeze it after forking.\n+\n+        This is done to prevent memory increase due to COW (Copy-on-Write) by moving all\n+        existing objects to the permanent generation before forking the process. After forking,\n+        unfreeze is called to ensure there is no impact on gc operations\n+        in the original running process.\n+\n+        Ref: https://docs.python.org/3/library/gc.html#gc.freeze\n+        \"\"\"\n+        import gc\n+\n+        gc.freeze()\n+        try:\n+            for _ in range(spawn_number):\n+                self._spawn_worker()\n+        finally:\n+            gc.unfreeze()\n+\n     def sync(self) -> None:\n         \"\"\"Sync will get called periodically by the heartbeat method.\"\"\"\n         self._read_results()"
  },
  {
    "filename": "airflow-core/tests/unit/executors/test_local_executor.py",
    "status": "modified",
    "additions": 24,
    "deletions": 3,
    "patch": "@@ -17,6 +17,7 @@\n # under the License.\n from __future__ import annotations\n \n+import gc\n import multiprocessing\n import os\n from unittest import mock\n@@ -44,6 +45,11 @@\n \n \n class TestLocalExecutor:\n+    \"\"\"\n+    When the executor is started, end() must be called before the test finishes.\n+    Otherwise, subprocesses will remain running, preventing the test from terminating and causing a timeout.\n+    \"\"\"\n+\n     TEST_SUCCESS_COMMANDS = 5\n \n     def test_sentry_integration(self):\n@@ -55,6 +61,20 @@ def test_is_local_default_value(self):\n     def test_serve_logs_default_value(self):\n         assert LocalExecutor.serve_logs\n \n+    @skip_spawn_mp_start\n+    @mock.patch.object(gc, \"unfreeze\")\n+    @mock.patch.object(gc, \"freeze\")\n+    def test_executor_worker_spawned(self, mock_freeze, mock_unfreeze):\n+        executor = LocalExecutor(parallelism=5)\n+        executor.start()\n+\n+        mock_freeze.assert_called_once()\n+        mock_unfreeze.assert_called_once()\n+\n+        assert len(executor.workers) == 5\n+\n+        executor.end()\n+\n     @skip_spawn_mp_start\n     @mock.patch(\"airflow.sdk.execution_time.supervisor.supervise\")\n     def test_execution(self, mock_supervise):\n@@ -86,11 +106,12 @@ def fake_supervise(ti, **kwargs):\n         mock_supervise.side_effect = fake_supervise\n \n         executor = LocalExecutor(parallelism=2)\n-        executor.start()\n-\n-        assert executor.result_queue.empty()\n \n         with spy_on(executor._spawn_worker) as spawn_worker:\n+            executor.start()\n+\n+            assert executor.result_queue.empty()\n+\n             for ti in success_tis:\n                 executor.queue_workload(\n                     workloads.ExecuteTask("
  },
  {
    "filename": "airflow-core/tests/unit/executors/test_local_executor_check_workers.py",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "patch": "@@ -101,7 +101,7 @@ def test_spawn_worker_when_needed(setup_executor):\n     executor.activity_queue.empty.return_value = False\n     executor.workers = {}\n     executor._check_workers()\n-    executor._spawn_worker.assert_called_once()\n+    executor._spawn_worker.assert_called()\n \n \n def test_no_spawn_if_parallelism_reached(setup_executor):\n@@ -133,4 +133,4 @@ def test_spawn_worker_when_we_have_parallelism_left(setup_executor):\n     executor.activity_queue.empty.return_value = False\n     executor._spawn_worker.reset_mock()\n     executor._check_workers()\n-    executor._spawn_worker.assert_called_once()\n+    executor._spawn_worker.assert_called()"
  }
]